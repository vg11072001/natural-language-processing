## [Transformer](https://jalammar.github.io/illustrated-transformer/) :huggingface.co/docs/transformers/
![image](https://user-images.githubusercontent.com/67424390/210357353-2b203cab-73a3-4df6-9410-80291dbfa9c2.png)
#### Step 1: Install Transformer.
#### Step 2: Call the pretrained model.
#### Step 3: Call the tokenizer of that particular pretrained model and encode the text in ex. seq2seq manner.
#### Step 4: Convert these encoding into Dataset objects. (Different objects of dataset for tensorflow - tensors and pytorch)
#### Step 5:  Translate and decode the elements in batch

## [BERT](https://jalammar.github.io/illustrated-bert/): 
![image](https://user-images.githubusercontent.com/67424390/210302799-ca5a509a-c473-43ee-b8a3-cd8fa585166e.png)


### First

* [2_Fine Tuning Pretrained Model On Custom Dataset Using ðŸ¤— Transformer: Custom_Sentiment_Analysis ](https://github.com/krishnaik06/Huggingfacetransformer/blob/main/Custom_Sentiment_Analysis.ipynb)

### Second
* [NLP: Implementing BERT and Transformers from Scratch](https://www.youtube.com/watch?v=EPa98fyxZ-s)
  * [Bert](https://github.com/msaroufim/RLnotes/blob/master/bert.md)
  * [Transformer](https://github.com/msaroufim/RLnotes/blob/master/transformer.md)


### Third - Official Hugging Face site
* [ðŸ¤— Transformers Notebooks](https://huggingface.co/docs/transformers/main/en/notebooks)
* [Tutorials by Hugging face for fine tune, processing, etc](https://huggingface.co/docs/transformers/training)
* [Summary of the tasks](https://huggingface.co/docs/transformers/task_summary)

## Refrences 
* https://www.youtube.com/playlist?list=PLZoTAELRMXVOTsz2jZl2Oq3ntWPoKRKwv
* https://neptune.ai/blog/natural-language-processing-with-hugging-face-and-transformers
